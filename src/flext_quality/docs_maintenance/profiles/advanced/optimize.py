#!/usr/bin/env python3
"""Documentation Content Optimization and Enhancement System.

Automatically optimizes and enhances documentation content for better quality,
readability, and maintainability.
"""

import argparse
import json
import operator
import os
import re
import time
from dataclasses import asdict, dataclass
from pathlib import Path
from typing import TypedDict

import yaml
from flext_core import (
    FlextConstants,
)

from flext_quality.docs_maintenance.utils import (
    get_backups_dir,
    get_docs_dir,
    get_project_root,
)


# Type definitions
class OptimizationInfo(TypedDict, total=False):
    """Information about an optimization applied."""

    type: str
    description: str
    line_number: int | None
    old_content: str | None
    new_content: str | None
    typo: str
    correction: str


class IssueInfo(TypedDict):
    """Information about an issue found during optimization."""

    type: str
    description: str
    line_number: int | None
    severity: str


class OptimizationSettings(TypedDict):
    """Optimization settings configuration."""

    auto_fix: bool
    create_backups: bool
    improve_formatting: bool
    fix_common_typos: bool
    enhance_code_blocks: bool
    max_line_length: int | None
    add_toc_to_long_docs: bool
    toc_min_headings: int


class OptimizationContentSettings(TypedDict):
    """Content settings for optimization."""

    common_typos: dict[str, str]


class OptimizationConfig(TypedDict):
    """Configuration for content optimization."""

    optimization: OptimizationSettings
    content: OptimizationContentSettings


# Constants for optimization
CODE_BLOCK_MARKER_MIN_LENGTH: int = FlextConstants.Network.MIN_PORT
LONG_PARAGRAPH_WORD_LIMIT: int = FlextConstants.Validation.PREVIEW_LENGTH * 4


@dataclass
class OptimizationResult:
    """Result of optimizing a single file."""

    file_path: str
    changes_made: int
    optimizations: list[OptimizationInfo]
    backup_created: bool
    issues_found: list[IssueInfo]


@dataclass
class OptimizationSummary:
    """Summary of optimization results."""

    total_files: int
    total_changes: int
    optimizations_by_type: dict[str, int]
    files_modified: int
    errors_encountered: int
    backup_files_created: list[str]


class ContentOptimizer:
    """Main content optimization class."""

    def __init__(self, config_path: str | None = None) -> None:
        """Initialize content optimizer with optional config path."""
        super().__init__()
        self.project_root = get_project_root()
        self.docs_dir = get_docs_dir(self.project_root)
        self.config: OptimizationConfig = self._load_config(config_path)
        self.backup_dir = get_backups_dir(self.project_root)

    def _load_config(self, config_path: str | None = None) -> OptimizationConfig:
        """Load configuration."""
        # Use plain dict for merging, then validate structure
        optimization_settings: dict[str, object] = {
            "auto_fix": True,
            "create_backups": True,
            "max_line_length": 120,
            "add_toc_to_long_docs": True,
            "toc_min_headings": 5,
            "fix_common_typos": True,
            "enhance_code_blocks": True,
            "improve_formatting": True,
        }
        content_settings: dict[str, object] = {
            "common_typos": {
                "teh": "the",
                "recieve": "receive",
                "seperate": "separate",
                "occurence": "occurrence",
                "defininig": "defining",
                "configuraiton": "configuration",
                "documenation": "documentation",
            },
        }

        if config_path and Path(config_path).exists():
            with Path(config_path).open(encoding="utf-8") as f:
                user_config = yaml.safe_load(f)
                if isinstance(user_config, dict):
                    opt_overrides = user_config.get("optimization", {})
                    if isinstance(opt_overrides, dict):
                        optimization_settings.update(opt_overrides)
                    content_overrides = user_config.get("content", {})
                    if isinstance(content_overrides, dict):
                        content_settings.update(content_overrides)

        return self._build_optimization_config(optimization_settings, content_settings)

    def _build_optimization_config(
        self,
        opt: dict[str, object],
        content: dict[str, object],
    ) -> OptimizationConfig:
        """Build OptimizationConfig from dictionaries."""
        common_typos = content.get("common_typos", {})
        if not isinstance(common_typos, dict):
            common_typos = {}

        # Extract numeric values with proper type checking
        max_line_val = opt.get("max_line_length")
        max_line_length = (
            int(max_line_val) if isinstance(max_line_val, int | float | str) else None
        )

        toc_min_val = opt.get("toc_min_headings", 5)
        toc_min_headings = (
            int(toc_min_val) if isinstance(toc_min_val, int | float | str) else 5
        )

        return OptimizationConfig(
            optimization=OptimizationSettings(
                auto_fix=bool(opt.get("auto_fix", True)),
                create_backups=bool(opt.get("create_backups", True)),
                improve_formatting=bool(opt.get("improve_formatting", True)),
                fix_common_typos=bool(opt.get("fix_common_typos", True)),
                enhance_code_blocks=bool(opt.get("enhance_code_blocks", True)),
                max_line_length=max_line_length,
                add_toc_to_long_docs=bool(opt.get("add_toc_to_long_docs", True)),
                toc_min_headings=toc_min_headings,
            ),
            content=OptimizationContentSettings(
                common_typos={str(k): str(v) for k, v in common_typos.items()},
            ),
        )

    def optimize_file(
        self,
        file_path: str,
        *,
        dry_run: bool = False,
    ) -> OptimizationResult:
        """Optimize a single documentation file."""
        try:
            with Path(file_path).open(encoding="utf-8") as f:
                original_content = f.read()
        except Exception as e:
            return OptimizationResult(
                file_path=file_path,
                changes_made=0,
                optimizations=[],
                backup_created=False,
                issues_found=[
                    {
                        "type": "read_error",
                        "description": f"Failed to read file: {e}",
                        "line_number": None,
                        "severity": "error",
                    },
                ],
            )

        content = original_content
        optimizations: list[OptimizationInfo] = []
        issues: list[IssueInfo] = []

        # Apply various optimizations
        content, file_optimizations = self._optimize_content(content)
        optimizations.extend(file_optimizations)

        # Generate table of contents if needed
        if self.config["optimization"]["add_toc_to_long_docs"]:
            toc_result = self._add_table_of_contents(content)
            if toc_result["added"]:
                content = str(toc_result["content"])
                optimizations.append({
                    "type": "toc_added",
                    "description": "Added table of contents to long document",
                })

        # Check for issues
        issues.extend(self._check_for_issues(content, file_path))

        changes_made = len(optimizations)

        # Create backup if changes were made
        backup_created = False
        if (
            changes_made > 0
            and self.config["optimization"]["create_backups"]
            and not dry_run
        ):
            backup_path = self._create_backup(file_path, original_content)
            backup_created = backup_path is not None

        # Write optimized content
        if not dry_run and content != original_content:
            try:
                with Path(file_path).open("w", encoding="utf-8") as f:
                    f.write(str(content))
            except Exception as e:
                issues.append({
                    "type": "write_error",
                    "description": f"Failed to write optimized content: {e}",
                    "line_number": None,
                    "severity": "error",
                })

        return OptimizationResult(
            file_path=file_path,
            changes_made=changes_made,
            optimizations=optimizations,
            backup_created=backup_created,
            issues_found=issues,
        )

    def _optimize_content(
        self,
        content: str,
    ) -> tuple[str, list[OptimizationInfo]]:
        """Apply content optimizations."""
        optimizations: list[OptimizationInfo] = []

        # Fix trailing whitespace
        if self.config["optimization"]["improve_formatting"]:
            content.count("\n")
            lines = content.split("\n")
            cleaned_lines = [line.rstrip() for line in lines]
            new_content = "\n".join(cleaned_lines)

            if new_content != content:
                content = new_content
                optimizations.append({
                    "type": "trailing_whitespace",
                    "description": "Removed trailing whitespace from lines",
                })

        # Fix common typos
        if self.config["optimization"]["fix_common_typos"]:
            for typo, correction in self.config["content"]["common_typos"].items():
                pattern = rf"\b{re.escape(typo)}\b"
                if re.search(pattern, content, re.IGNORECASE):
                    content = re.sub(pattern, correction, content, flags=re.IGNORECASE)
                    optimizations.append({
                        "type": "typo_fix",
                        "typo": typo,
                        "correction": correction,
                        "description": f"Fixed typo: {typo} â†’ {correction}",
                    })

        # Enhance code blocks
        if self.config["optimization"]["enhance_code_blocks"]:
            content, code_optimizations = self._enhance_code_blocks(content)
            optimizations.extend(code_optimizations)

        # Fix line length issues
        if self.config["optimization"]["max_line_length"]:
            content, length_optimizations = self._fix_line_lengths(content)
            optimizations.extend(length_optimizations)

        return content, optimizations

    def _enhance_code_blocks(self, content: str) -> tuple[str, list[OptimizationInfo]]:
        """Enhance code blocks with better formatting."""
        optimizations: list[OptimizationInfo] = []

        # Find code blocks without language specification
        lines = content.split("\n")
        in_code_block = False

        for i, line in enumerate(lines):
            if line.strip().startswith("```"):
                if not in_code_block:
                    # Start of code block
                    in_code_block = True
                    # Check if language is specified
                    code_marker = line.strip()
                    if (
                        code_marker == "```"
                        or len(code_marker) == CODE_BLOCK_MARKER_MIN_LENGTH
                    ):
                        # Try to detect language from content
                        detected_lang = self._detect_code_language(lines, i)
                        if detected_lang:
                            lines[i] = f"``` {detected_lang}"
                            optimizations.append({
                                "type": "code_block_language",
                                "description": f"Added language specification: {detected_lang}",
                                "line_number": i + 1,
                            })
                else:
                    # End of code block
                    in_code_block = False

        return "\n".join(lines), optimizations

    def _detect_code_language(self, lines: list[str], start_index: int) -> str | None:
        """Detect programming language from code block content."""
        # Look at the next few lines for language clues
        for i in range(start_index + 1, min(start_index + 10, len(lines))):
            line = lines[i].strip()
            if line.startswith("```"):
                break

            # Python indicators
            if re.search(r"\bdef\b|\bimport\b|\bfrom\b.*import|\bclass\b", line):
                return "python"

            # Bash/shell indicators
            if re.search(r"\$\{|\becho\b|\bgrep\b|\bsed\b|\bawk\b", line):
                return "bash"

            # JSON indicators
            if re.search(r'^\s*{\s*"|^"', line):
                return "json"

            # YAML indicators
            if re.search(r"^\s*\w+:\s|^---", line):
                return "yaml"

            # JavaScript indicators
            if re.search(r"\bfunction\b|\bconst\b|\blet\b|\bvar\b", line):
                return "javascript"

        return None

    def _fix_line_lengths(self, content: str) -> tuple[str, list[OptimizationInfo]]:
        """Fix overly long lines by breaking them appropriately."""
        optimizations: list[OptimizationInfo] = []
        max_length = self.config["optimization"]["max_line_length"]

        if max_length is None:
            return content, optimizations

        lines = content.split("\n")
        for i, line in enumerate(lines):
            if (
                len(line) > max_length
                and not line.strip().startswith("```")
                and "," in line
                and len(line) > max_length + 20
            ):
                # Try to break at natural points
                # Break after comma
                parts = line.split(",")
                if len(parts) > 1:
                    new_lines = []
                    current_line = parts[0]
                    for part in parts[1:]:
                        if len(current_line + "," + part) > max_length:
                            new_lines.append(current_line + ",")
                            current_line = "    " + part  # Indent continuation
                        else:
                            current_line += "," + part
                    new_lines.append(current_line)

                    lines[i] = "\n".join(new_lines)
                    optimizations.append({
                        "type": "line_length",
                        "description": f"Fixed long line by breaking at commas (line {i + 1})",
                    })

        return "\n".join(lines), optimizations

    def _add_table_of_contents(
        self,
        content: str,
    ) -> dict[str, str | bool]:
        """Add table of contents to long documents."""
        lines = content.split("\n")

        # Count headings
        headings = []
        for i, line in enumerate(lines):
            match = re.match(r"^(#{1,6})\s+(.+)$", line)
            if match:
                level = len(match.group(1))
                title = match.group(2)
                headings.append((i, level, title))

        # Only add TOC if enough headings and not already present
        min_headings = self.config["optimization"]["toc_min_headings"]
        if len(headings) >= min_headings and not self._has_table_of_contents(content):
            # Generate TOC
            toc_lines = ["## Table of Contents", ""]
            for _line_num, level, title in headings:
                indent = "  " * (level - 1)
                # Create anchor link
                anchor = re.sub(r"[^\w\s-]", "", title).replace(" ", "-").lower()
                toc_lines.append(f"{indent}- [{title}](#{anchor})")

            toc_lines.append("")
            toc_content = "\n".join(toc_lines)

            # Insert after the first heading
            first_heading_idx = headings[0][0]
            lines.insert(first_heading_idx + 1, toc_content)

            return {"added": True, "content": "\n".join(lines)}

        return {"added": False, "content": content}

    def _has_table_of_contents(self, content: str) -> bool:
        """Check if document already has a table of contents."""
        return (
            re.search(
                r"## Table of Contents|## Contents|## TOC",
                content,
                re.IGNORECASE,
            )
            is not None
        )

    def _check_for_issues(self, content: str, file_path: str) -> list[IssueInfo]:
        """Check for potential issues in the content."""
        issues: list[IssueInfo] = []

        # Check for broken internal links
        internal_links = re.findall(r"\[([^\]]+)\]\(([^)]+)\)", content)
        for _text, url in internal_links:
            if not url.startswith(("http", "https", "#")):
                # Check if relative file exists
                file_dir = Path(file_path).parent
                full_path = str(file_dir / url)
                if not Path(full_path).exists():
                    issues.append({
                        "type": "broken_link",
                        "description": f"Broken internal link: {url}",
                        "line_number": None,
                        "severity": "warning",
                    })

        # Check for very long paragraphs
        paragraphs = re.split(r"\n\s*\n", content)
        for para in paragraphs:
            word_count = len(para.split())
            if word_count > LONG_PARAGRAPH_WORD_LIMIT:  # Very long paragraph
                issues.append({
                    "type": "long_paragraph",
                    "description": f"Very long paragraph ({word_count} words) - consider breaking up",
                    "line_number": None,
                    "severity": "info",
                })

        return issues

    def _create_backup(self, file_path: str, content: str) -> str | None:
        """Create a backup of the original file."""
        try:
            filename = Path(file_path).name
            timestamp = __import__("time").strftime("%Y%m%d_%H%M%S")
            backup_name = f"{filename}.{timestamp}.backup"
            backup_path = str(self.backup_dir / backup_name)

            with Path(backup_path).open("w", encoding="utf-8") as f:
                f.write(content)

            return backup_path
        except Exception:
            return None

    def optimize_directory(
        self,
        directory: str,
        *,
        dry_run: bool = False,
    ) -> list[OptimizationResult]:
        """Optimize all files in a directory."""
        results = []

        for root, dirs, files in os.walk(directory):
            # Skip excluded directories
            dirs[:] = [d for d in dirs if not self._is_excluded(str(Path(root) / d))]

            for file in files:
                if file.endswith((".md", ".mdx")):
                    file_path = str(Path(root) / file)
                    if not self._is_excluded(file_path):
                        result = self.optimize_file(file_path, dry_run=dry_run)
                        results.append(result)

        return results

    def _is_excluded(self, path: str) -> bool:
        """Check if path is excluded."""
        # Basic exclusion - could be made configurable
        return ".git" in path or "node_modules" in path or "backups" in path

    def generate_summary(
        self,
        results: list[OptimizationResult],
    ) -> OptimizationSummary:
        """Generate summary of optimization results."""
        total_files = len(results)
        total_changes = sum(r.changes_made for r in results)

        optimizations_by_type = {}
        files_modified = sum(1 for r in results if r.changes_made > 0)
        errors_encountered = sum(1 for r in results if r.issues_found)
        backup_files_created = []

        for result in results:
            for opt in result.optimizations:
                opt_type = opt.get("type", "unknown")
                optimizations_by_type[opt_type] = (
                    optimizations_by_type.get(opt_type, 0) + 1
                )

            if result.backup_created:
                backup_files_created.append(result.file_path)

        return OptimizationSummary(
            total_files=total_files,
            total_changes=total_changes,
            optimizations_by_type=optimizations_by_type,
            files_modified=files_modified,
            errors_encountered=errors_encountered,
            backup_files_created=backup_files_created,
        )


def main() -> None:
    """Main entry point for documentation optimization system."""
    args = _parse_optimize_args()
    optimizer = ContentOptimizer(args.config)

    results = optimizer.optimize_directory(args.directory, dry_run=args.dry_run)
    summary = optimizer.generate_summary(results)

    _save_optimization_results(args.output, results, summary)
    _print_optimization_summary(summary, results, args)


def _parse_optimize_args() -> argparse.Namespace:
    """Parse command line arguments for optimization.

    Returns:
        Parsed arguments namespace

    """
    parser = argparse.ArgumentParser(
        description="Documentation Content Optimization and Enhancement System",
    )
    parser.add_argument("directory", help="Directory to optimize")
    parser.add_argument("--config", help="Configuration file path")
    parser.add_argument("--output", "-o", help="Output file for results")
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Show what would be changed without making changes",
    )
    parser.add_argument(
        "--enhance-all",
        action="store_true",
        help="Apply all available optimizations",
    )
    parser.add_argument(
        "--fix-typos",
        action="store_true",
        help="Only fix common typos",
    )
    parser.add_argument(
        "--add-toc",
        action="store_true",
        help="Only add table of contents to long documents",
    )
    parser.add_argument("--verbose", "-v", action="store_true", help="Verbose output")
    return parser.parse_args()


def _save_optimization_results(
    output_path: str | None,
    results: list[OptimizationResult],
    summary: OptimizationSummary,
) -> None:
    """Save optimization results to file.

    Args:
        output_path: Path to output file
        results: Optimization results
        summary: Summary object

    """
    if not output_path:
        return

    output_data = {
        "timestamp": time.time(),
        "summary": asdict(summary),
        "results": [asdict(r) for r in results],
    }
    with Path(output_path).open("w", encoding="utf-8") as f:
        json.dump(output_data, f, indent=2, default=str)


def _print_optimization_summary(
    summary: OptimizationSummary,
    results: list[OptimizationResult],
    args: argparse.Namespace,
) -> None:
    """Print optimization summary.

    Args:
        summary: Summary object
        results: Optimization results
        args: Command line arguments

    """
    if summary.optimizations_by_type:
        for opt_type, count in sorted(
            summary.optimizations_by_type.items(),
            key=operator.itemgetter(1),
            reverse=True,
        ):
            _ = (opt_type, count)  # Process if needed

    if summary.backup_files_created and args.verbose:
        for file_path in summary.backup_files_created[:5]:
            _ = file_path  # Process if needed

    _ = (
        (summary.files_modified / summary.total_files * 100)
        if summary.total_files > 0
        else 0
    )

    # Show files with most changes
    if args.verbose and results:
        files_by_changes = sorted(
            [(r.file_path, r.changes_made) for r in results if r.changes_made > 0],
            key=operator.itemgetter(1),
            reverse=True,
        )

        if files_by_changes:
            for file_path, changes in files_by_changes[:5]:
                _ = (file_path, changes)  # Process if needed


if __name__ == "__main__":
    main()
